
The paper we will study in this homework is \textbf{`Understanding deep learning requires rethinking generalization'}, presented at the International Conference on Learning Representations (ICLR) in 2017.

The paper presents a set of interesting experiments and results to explore the phenomenon of generalization in deep neural networks, i.e, the difference in performance on the training and test sets, and the role of explicit and implicit regularization towards achieving this. The paper can be viewed \href{https://arxiv.org/abs/1611.03530}{here}.

Please discuss the following:
\begin{enumerate}
\item
Briefly summarize the key contributions, strengths and weaknesses of this paper.

\item
What is your personal takeaway from this paper? This could be expressed either in terms of relating the approaches adopted in this paper to your traditional understanding of learning parameterized models, or potential future directions of research in the area which the authors haven't addressed, or anything else that struck you as being noteworthy. 
\end{enumerate}

\textbf{Guidelines}: Please restrict your reviews to no more than 350 words (total length for answers to both the above questions).